{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "deeeplarning-pytorch.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/alfonso777/deeplearning-rehearsal/blob/master/deeeplarning_pytorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VjlylrU8oq4g",
        "colab_type": "text"
      },
      "source": [
        "# Deep Learning with PyTorch\n",
        "\n",
        "**Author**: Jhosimar George Arias Figueroa\n",
        "\n",
        "Based on ([PyTorch Tutorials](https://pytorch.org/tutorials/)) with some modifications."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qiAJfPvNpctm",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "What is PyTorch?\n",
        "================\n",
        "\n",
        "It’s a Python-based scientific computing package targeted at two sets of\n",
        "audiences:\n",
        "\n",
        "-  A replacement for NumPy to use the power of GPUs\n",
        "-  a deep learning research platform that provides maximum flexibility\n",
        "   and speed"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eHEGPSKLpzou",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LME9zEt6yhAw",
        "colab_type": "text"
      },
      "source": [
        "Getting Started\n",
        "---------------\n",
        "\n",
        "Tensors\n",
        "-------\n",
        "\n",
        "Tensors are similar to NumPy’s ndarrays, with the addition being that\n",
        "Tensors can also be used on a GPU to accelerate computing.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C0UrUxtIzkKI",
        "colab_type": "text"
      },
      "source": [
        "Construct a 5x3 matrix, uninitialized:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pLDiWrNNzliC",
        "colab_type": "code",
        "outputId": "c42fc877-7c04-4fa9-b111-d61057e9f545",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "x = torch.empty(5, 3)\n",
        "print(x)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[7.9914e-37, 0.0000e+00, 0.0000e+00],\n",
            "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
            "        [0.0000e+00, 0.0000e+00, 2.8026e-45],\n",
            "        [0.0000e+00, 1.1210e-44, 0.0000e+00],\n",
            "        [1.4013e-45, 0.0000e+00, 1.0643e+15]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4xnvHMnJ0M_e",
        "colab_type": "text"
      },
      "source": [
        "Construct a randomly initialized matrix:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gu1ZwH_J0W8Q",
        "colab_type": "code",
        "outputId": "b64d9b1e-27d8-49a9-fe43-36211ea6c917",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "x = torch.rand(5, 3)\n",
        "print(x)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[0.8469, 0.4929, 0.2324],\n",
            "        [0.2289, 0.8863, 0.2346],\n",
            "        [0.1516, 0.3457, 0.7683],\n",
            "        [0.8728, 0.7493, 0.0541],\n",
            "        [0.7661, 0.7095, 0.7358]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6JKHLo730a3B",
        "colab_type": "text"
      },
      "source": [
        "Construct a matrix filled zeros and of dtype long:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VZTIYdrt0efn",
        "colab_type": "code",
        "outputId": "533629e5-47cf-49c9-8ee6-e622c4b2d9a6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "x = torch.zeros(5, 3, dtype=torch.long)\n",
        "print(x)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[0, 0, 0],\n",
            "        [0, 0, 0],\n",
            "        [0, 0, 0],\n",
            "        [0, 0, 0],\n",
            "        [0, 0, 0]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rg5GhH800ge_",
        "colab_type": "text"
      },
      "source": [
        "Construct a tensor directly from data:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2f1oH_zB0izE",
        "colab_type": "code",
        "outputId": "39280ccb-8f96-4b2a-aab1-9d1a0e216cc8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "x = torch.tensor([5.5, 3])\n",
        "print(x)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([5.5000, 3.0000])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EpM___ZS08c0",
        "colab_type": "text"
      },
      "source": [
        "or create a tensor based on an existing tensor. These methods\n",
        "will reuse properties of the input tensor, e.g. dtype, unless\n",
        "new values are provided by user"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XjCklYfS09Mb",
        "colab_type": "code",
        "outputId": "c9f49b47-2057-40fe-c0ea-324e4ade78ec",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "x = x.new_ones(5, 3, dtype=torch.double)      # new_* methods take in sizes\n",
        "print(x)\n",
        "\n",
        "x = torch.randn_like(x, dtype=torch.float)    # override dtype!\n",
        "print(x)                                      # result has the same size"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[1., 1., 1.],\n",
            "        [1., 1., 1.],\n",
            "        [1., 1., 1.],\n",
            "        [1., 1., 1.],\n",
            "        [1., 1., 1.]], dtype=torch.float64)\n",
            "tensor([[ 1.6221, -2.0021,  0.0463],\n",
            "        [ 0.4164,  0.5748,  0.9455],\n",
            "        [ 0.3360, -0.8761,  0.1201],\n",
            "        [-0.5228,  1.7988,  0.6103],\n",
            "        [-0.9601, -0.2519, -3.2160]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rg-cUr0A1Zrt",
        "colab_type": "text"
      },
      "source": [
        "Get its size:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UA5jyXG21hOQ",
        "colab_type": "code",
        "outputId": "fe344226-6bd3-4843-bb9f-54f42cc3160b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(x.size())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([5, 3])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iI5lPw-A1jbJ",
        "colab_type": "text"
      },
      "source": [
        "<div class=\"alert alert-info\"><h4>Note</h4><p>``torch.Size`` is in fact a tuple, so it supports all tuple operations.</p></div>\n",
        "\n",
        "Operations\n",
        "----------\n",
        "\n",
        "There are multiple syntaxes for operations. In the following\n",
        "example, we will take a look at the addition operation.\n",
        "\n",
        "Addition: syntax 1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hw7JfNm41vj-",
        "colab_type": "code",
        "outputId": "7637ea0b-1147-49ac-9ef8-bf926af950d5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "y = torch.rand(5, 3)\n",
        "print(x + y)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[ 2.6177, -1.5782,  0.3608],\n",
            "        [ 0.5678,  0.7580,  1.6895],\n",
            "        [ 0.7335, -0.4324,  0.8854],\n",
            "        [-0.3362,  2.2373,  1.5348],\n",
            "        [-0.6646,  0.3290, -2.6985]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R1eRTVdO1wKG",
        "colab_type": "text"
      },
      "source": [
        "Addition: syntax 2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5fS2ffYE1xmG",
        "colab_type": "code",
        "outputId": "ac36a3e9-ba28-4604-f245-cea46851e658",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "print(torch.add(x, y))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[ 2.6177, -1.5782,  0.3608],\n",
            "        [ 0.5678,  0.7580,  1.6895],\n",
            "        [ 0.7335, -0.4324,  0.8854],\n",
            "        [-0.3362,  2.2373,  1.5348],\n",
            "        [-0.6646,  0.3290, -2.6985]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZUQq8p5c1zLT",
        "colab_type": "text"
      },
      "source": [
        "Addition: providing an output tensor as argument"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nCmp7xpN11FY",
        "colab_type": "code",
        "outputId": "22d8c875-ca01-489b-d48e-5f4dc0ad1e69",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "result = torch.empty(5, 3)\n",
        "torch.add(x, y, out=result)\n",
        "print(result)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[ 2.6177, -1.5782,  0.3608],\n",
            "        [ 0.5678,  0.7580,  1.6895],\n",
            "        [ 0.7335, -0.4324,  0.8854],\n",
            "        [-0.3362,  2.2373,  1.5348],\n",
            "        [-0.6646,  0.3290, -2.6985]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bLTpiCUp12ep",
        "colab_type": "text"
      },
      "source": [
        "Addition: in-place"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mp8HuU1D14FS",
        "colab_type": "code",
        "outputId": "faf6824a-2ade-46e0-9eba-4dd3fc42c382",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "# adds x to y\n",
        "y.add_(x)\n",
        "print(y)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[ 2.6177, -1.5782,  0.3608],\n",
            "        [ 0.5678,  0.7580,  1.6895],\n",
            "        [ 0.7335, -0.4324,  0.8854],\n",
            "        [-0.3362,  2.2373,  1.5348],\n",
            "        [-0.6646,  0.3290, -2.6985]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PKxTf--52NMx",
        "colab_type": "text"
      },
      "source": [
        "<div class=\"alert alert-info\"><h4>Note</h4><p>Any operation that mutates a tensor in-place is post-fixed with an ``_``.\n",
        "    For example: ``x.copy_(y)``, ``x.t_()``, will change ``x``.</p></div>\n",
        "\n",
        "Indexing\n",
        "--------\n",
        "\n",
        "You can use standard NumPy-like indexing with all bells and whistles!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1qAaYgHM2S4z",
        "colab_type": "code",
        "outputId": "a0a40e5d-d6fe-4a40-bba9-0c23d7273b2d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(x[:, 1])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([-2.0021,  0.5748, -0.8761,  1.7988, -0.2519])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_yDbzVPS2aIM",
        "colab_type": "text"
      },
      "source": [
        "Resizing: If you want to resize/reshape tensor, you can use ``torch.view``:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tYbjYCEV2aq3",
        "colab_type": "code",
        "outputId": "4a071dba-52e0-4daf-b7b1-e7e99335d66a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "x = torch.randn(4, 4)\n",
        "y = x.view(16)\n",
        "z = x.view(-1, 8)  # the size -1 is inferred from other dimensions\n",
        "print(x.size(), y.size(), z.size())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([4, 4]) torch.Size([16]) torch.Size([2, 8])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D5JvnAHx2jcQ",
        "colab_type": "text"
      },
      "source": [
        "If you have a one element tensor, use ``.item()`` to get the value as a\n",
        "Python number"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gyl2eQIZ2lXk",
        "colab_type": "code",
        "outputId": "b8ed7079-ac41-40eb-cb3a-46b20e6ba466",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "x = torch.randn(1)\n",
        "print(x)\n",
        "print(x.item())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([0.4673])\n",
            "0.4672677516937256\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MknJe_9o2zsW",
        "colab_type": "text"
      },
      "source": [
        "**Read later:**\n",
        "\n",
        "\n",
        "  100+ Tensor operations, including transposing, indexing, slicing,\n",
        "  mathematical operations, linear algebra, random numbers, etc.,\n",
        "  are described [here](http://pytorch.org/docs/torch).\n",
        "\n",
        "NumPy Bridge\n",
        "------------\n",
        "\n",
        "Converting a Torch Tensor to a NumPy array and vice versa is a breeze.\n",
        "\n",
        "The Torch Tensor and NumPy array will share their underlying memory\n",
        "locations, and changing one will change the other.\n",
        "\n",
        "Converting a Torch Tensor to a NumPy Array\n",
        "------------------------------------------"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q_Ba16u222cI",
        "colab_type": "code",
        "outputId": "36d8adbb-5c1c-417a-8ded-2a923e3df492",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "a = torch.ones(5)\n",
        "print(a)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([1., 1., 1., 1., 1.])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hNqKxqrs3XJC",
        "colab_type": "code",
        "outputId": "ae030f6a-06a5-473e-ca47-daa5f17e08e8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "b = a.numpy()\n",
        "print(b)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1. 1. 1. 1. 1.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BmSodfeP3aVe",
        "colab_type": "text"
      },
      "source": [
        "See how the numpy array changed in value."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CG5pYsEl3bkH",
        "colab_type": "code",
        "outputId": "5929bb07-85e1-42ff-fe30-1887374b6843",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "a.add_(1)\n",
        "print(a)\n",
        "print(b)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([2., 2., 2., 2., 2.])\n",
            "[2. 2. 2. 2. 2.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-PLuIrT53fAz",
        "colab_type": "text"
      },
      "source": [
        "Converting NumPy Array to Torch Tensor\n",
        "--------------------------------------\n",
        "See how changing the np array changed the Torch Tensor automatically"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "esDuzSyH3h1m",
        "colab_type": "code",
        "outputId": "3dc12591-a9d7-4a9d-f145-1cd22f4a9144",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import numpy as np\n",
        "a = np.ones(5)\n",
        "b = torch.from_numpy(a)\n",
        "np.add(a, 1, out=a)\n",
        "print(a)\n",
        "print(b)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[2. 2. 2. 2. 2.]\n",
            "tensor([2., 2., 2., 2., 2.], dtype=torch.float64)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eO7tF0cs3o6d",
        "colab_type": "text"
      },
      "source": [
        "All the Tensors on the CPU except a CharTensor support converting to\n",
        "NumPy and back.\n",
        "\n",
        "CUDA Tensors\n",
        "------------\n",
        "\n",
        "Tensors can be moved onto any device using the ``.to`` method."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EZeAlGD24jDq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# let us run this cell only if CUDA is available\n",
        "# We will use ``torch.device`` objects to move tensors in and out of GPU\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda\")          # a CUDA device object\n",
        "    y = torch.ones_like(x, device=device)  # directly create a tensor on GPU\n",
        "    x = x.to(device)                       # or just use strings ``.to(\"cuda\")``\n",
        "    z = x + y\n",
        "    print(z)\n",
        "    print(z.to(\"cpu\", torch.double))       # ``.to`` can also change dtype together!"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tbr7NAEn6u5M",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "Autograd: Automatic Differentiation\n",
        "===================================\n",
        "\n",
        "Central to all neural networks in PyTorch is the ``autograd`` package.\n",
        "Let’s first briefly visit this, and we will then go to training our\n",
        "first neural network.\n",
        "\n",
        "\n",
        "The ``autograd`` package provides automatic differentiation for all operations\n",
        "on Tensors. It is a define-by-run framework, which means that your backprop is\n",
        "defined by how your code is run, and that every single iteration can be\n",
        "different.\n",
        "\n",
        "Let us see this in more simple terms with some examples.\n",
        "\n",
        "Tensor\n",
        "--------\n",
        "\n",
        "``torch.Tensor`` is the central class of the package. If you set its attribute ``.requires_grad`` as ``True``, it starts to track all operations on it. When\n",
        "you finish your computation you can call ``.backward()`` and have all the\n",
        "gradients computed automatically. The gradient for this tensor will be\n",
        "accumulated into ``.grad`` attribute.\n",
        "\n",
        "To stop a tensor from tracking history, you can call ``.detach()`` to detach it from the computation history, and to prevent future computation from being tracked.\n",
        "\n",
        "If you want to compute the derivatives, you can call ``.backward()`` on\n",
        "a ``Tensor``. If ``Tensor`` is a scalar (i.e. it holds a one element\n",
        "data), you don’t need to specify any arguments to ``backward()``,\n",
        "however if it has more elements, you need to specify a ``gradient``\n",
        "argument that is a tensor of matching shape."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Av4yCHTx7ig1",
        "colab_type": "text"
      },
      "source": [
        "Create a tensor and set requires_grad=True to track computation with it"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CvRaW8EE7AEy",
        "colab_type": "code",
        "outputId": "0114654a-1108-40bd-bc3f-039f8e1d64c7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "x = torch.ones(2, 2, requires_grad=True)\n",
        "print(x)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[1., 1.],\n",
            "        [1., 1.]], requires_grad=True)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tv604DqR7m6G",
        "colab_type": "text"
      },
      "source": [
        "Do an operation of tensor:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TDrcxL5e7w_o",
        "colab_type": "code",
        "outputId": "3c56249b-a673-4bcc-8a6a-c80c40737ed8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "y = x + 2\n",
        "print(y)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[3., 3.],\n",
            "        [3., 3.]], grad_fn=<AddBackward0>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ot-K4o5bCm4o",
        "colab_type": "text"
      },
      "source": [
        "Do more operations on y"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eUNjW6CYCnU-",
        "colab_type": "code",
        "outputId": "933aab17-2707-452c-e52b-8fe4145af2d1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "z = y * y * 3\n",
        "out = z.mean()\n",
        "\n",
        "print(z, out)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[27., 27.],\n",
            "        [27., 27.]], grad_fn=<MulBackward0>) tensor(27., grad_fn=<MeanBackward0>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R6ZjhCeTCpU8",
        "colab_type": "text"
      },
      "source": [
        "``.requires_grad_( ... )`` changes an existing Tensor's ``requires_grad``\n",
        "flag in-place. The input flag defaults to ``False`` if not given."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "faRtw2lmCsAn",
        "colab_type": "code",
        "outputId": "b38193c0-bed0-46c0-dfef-1827343a17d8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "a = torch.randn(2, 2)\n",
        "a = ((a * 3) / (a - 1))\n",
        "print(a.requires_grad)\n",
        "a.requires_grad_(True)\n",
        "print(a.requires_grad)\n",
        "b = (a * a).sum()\n",
        "print(b.grad_fn)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "False\n",
            "True\n",
            "<SumBackward0 object at 0x7f46d1c578d0>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D3OkO2AQC0lz",
        "colab_type": "text"
      },
      "source": [
        "Gradients\n",
        "---------\n",
        "Let's backprop now. Because ``out`` contains a single scalar, ``out.backward()`` is\n",
        "equivalent to ``out.backward(torch.tensor(1))``."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fo66V7-lC1FV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "out.backward()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fovfxAf2C23T",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "print gradients d(out)/dx"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ywzCJSOC8A6",
        "colab_type": "code",
        "outputId": "69d054a0-db72-4347-8fba-52be0b94ecb3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(x.grad)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[4.5000, 4.5000],\n",
            "        [4.5000, 4.5000]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AFaJch6NC9uE",
        "colab_type": "text"
      },
      "source": [
        "You should have got a matrix of ``4.5``. Let’s call the ``out``\n",
        "*Tensor* “$o$”.\n",
        "We have that $o = \\frac{1}{4}\\sum_i z_i$,\n",
        "$z_i = 3(x_i+2)^2$ and $z_i\\bigr\\rvert_{x_i=1} = 27$.\n",
        "Therefore,\n",
        "$\\frac{\\partial o}{\\partial x_i} = \\frac{3}{2}(x_i+2)$, hence\n",
        "$\\frac{\\partial o}{\\partial x_i}\\bigr\\rvert_{x_i=1} = \\frac{9}{2} = 4.5$.\n",
        "\n",
        "You can do many crazy things with autograd!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Nf3MhXQDAuV",
        "colab_type": "code",
        "outputId": "a3769ed5-a4c6-449a-c3b1-ef48059c0f1c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "x = torch.randn(3, requires_grad=True)\n",
        "\n",
        "y = x * 2\n",
        "while y.data.norm() < 1000:\n",
        "    y = y * 2\n",
        "\n",
        "print(y)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([-1044.6628,  -303.0750,   414.6512], grad_fn=<MulBackward0>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8fl6KhFBDDlf",
        "colab_type": "code",
        "outputId": "570ac708-049c-41a9-adf8-edbed86dfad1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "gradients = torch.tensor([0.1, 1.0, 0.0001], dtype=torch.float)\n",
        "y.backward(gradients)\n",
        "\n",
        "print(x.grad)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([5.1200e+01, 5.1200e+02, 5.1200e-02])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a1GGst-ODRO5",
        "colab_type": "text"
      },
      "source": [
        "You can also stop autograd from tracking history on Tensors\n",
        "with ``.requires_grad=True`` by wrapping the code block in\n",
        "``with torch.no_grad()``:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UbPhPn7lDRlo",
        "colab_type": "code",
        "outputId": "ac5d64d0-1e16-42da-a046-334c580ac65e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(x.requires_grad)\n",
        "print((x ** 2).requires_grad)\n",
        "\n",
        "with torch.no_grad():\n",
        "\tprint((x ** 2).requires_grad)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "True\n",
            "True\n",
            "False\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u1CW8vNQMeZg",
        "colab_type": "text"
      },
      "source": [
        "Let's see another example"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i1qMIuS-Mgfx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x = torch.tensor(1., requires_grad=True)\n",
        "w = torch.tensor(2., requires_grad=True)\n",
        "b = torch.tensor(3., requires_grad=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LmmbELA-Mkl3",
        "colab_type": "text"
      },
      "source": [
        "Build a computational graph"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "45FuKx8NMmOb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y = w * x + b    # y = 2 * x + 3"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hpxQUJ0RMny1",
        "colab_type": "text"
      },
      "source": [
        "Compute gradients"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UeXMRkmSMpLA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y.backward()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AOxBzdGOMrM4",
        "colab_type": "text"
      },
      "source": [
        "Print out the gradients."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ASh9N-7CMs5d",
        "colab_type": "code",
        "outputId": "faa688c0-9fad-4bc0-e319-311c7aa6306e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(x.grad)    # x.grad = 2 \n",
        "print(w.grad)    # w.grad = 1 \n",
        "print(b.grad)    # b.grad = 1 "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(2.)\n",
            "tensor(1.)\n",
            "tensor(1.)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sM8eOoxFDU-t",
        "colab_type": "text"
      },
      "source": [
        "**Read Later:**\n",
        "\n",
        "Documentation of ``autograd`` and ``Function`` is at\n",
        "http://pytorch.org/docs/autograd\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GpY2NJ4BYVjk",
        "colab_type": "text"
      },
      "source": [
        "Neural Networks\n",
        "===============\n",
        "\n",
        "Neural networks can be constructed using the ``torch.nn`` package.\n",
        "\n",
        "Now that you had a glimpse of ``autograd``, ``nn`` depends on\n",
        "``autograd`` to define models and differentiate them.\n",
        "An ``nn.Module`` contains layers, and a method ``forward(input)`` that\n",
        "returns the ``output``.\n",
        "\n",
        "For example, look at this network that classifies digit images:\n",
        "\n",
        "![alt text](https://pytorch.org/tutorials/_images/mnist.png)\n",
        "\n",
        "It is a simple feed-forward network. It takes the input, feeds it\n",
        "through several layers one after the other, and then finally gives the\n",
        "output.\n",
        "\n",
        "A typical training procedure for a neural network is as follows:\n",
        "\n",
        "- Define the neural network that has some learnable parameters (or\n",
        "  weights)\n",
        "- Iterate over a dataset of inputs\n",
        "- Process input through the network\n",
        "- Compute the loss (how far is the output from being correct)\n",
        "- Propagate gradients back into the network’s parameters\n",
        "- Update the weights of the network, typically using a simple update rule:\n",
        "  ``weight = weight - learning_rate * gradient``"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7l3YHL5pdYxp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torch.nn import functional as F"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WOlkDtbWd2kd",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "Fully Connected Networks\n",
        "------------------\n",
        "\n",
        "Let’s define a network:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GtTVNHlbar2O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Fully connected neural network with one hidden layer\n",
        "class NeuralNet(nn.Module):\n",
        "  def __init__(self, input_size, hidden_size, num_classes):\n",
        "    super(NeuralNet, self).__init__()\n",
        "    self.fc1 = nn.Linear(input_size, hidden_size) \n",
        "    self.relu = nn.ReLU()\n",
        "    self.fc2 = nn.Linear(hidden_size, num_classes)  \n",
        "    \n",
        "  def forward(self, x):\n",
        "    out = self.fc1(x)\n",
        "    out = self.relu(out)\n",
        "    out = self.fc2(out)\n",
        "    return out"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hHQHYd-NdUVG",
        "colab_type": "code",
        "outputId": "574aaad2-9f2a-46a7-eabd-4cda10841814",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "input_size = 20\n",
        "hidden_size = 15\n",
        "num_classes = 10\n",
        "\n",
        "model = NeuralNet(input_size, hidden_size, num_classes)\n",
        "print(model)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "NeuralNet(\n",
            "  (fc1): Linear(in_features=20, out_features=15, bias=True)\n",
            "  (relu): ReLU()\n",
            "  (fc2): Linear(in_features=15, out_features=10, bias=True)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-AOlJFnzezCE",
        "colab_type": "text"
      },
      "source": [
        "You just have to define the forward function, and the backward function (where gradients are computed) is automatically defined for you using autograd. You can use any of the Tensor operations in the forward function.\n",
        "\n",
        "The learnable parameters of a model are returned by model.parameters()"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4gev2eY5eFYE",
        "colab_type": "code",
        "outputId": "de314a32-c655-4021-ee3a-4629505349e7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "params = list(model.parameters())\n",
        "print(len(params))\n",
        "print(params[0].size())  # fc1 .weight"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "4\n",
            "torch.Size([15, 20])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RTeKPYSRfCxf",
        "colab_type": "text"
      },
      "source": [
        "Let's try a random input Note: Expected input size to this model was defined before."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "twSNH1IMe5QC",
        "colab_type": "code",
        "outputId": "c244a9c6-5fcd-4fd5-88e8-0c911ee2e934",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        }
      },
      "source": [
        "input = torch.randn(10, input_size)\n",
        "out = model(input)\n",
        "print(out)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[-0.3366, -0.3262,  0.1262,  0.1122, -0.1648,  0.0553,  0.2974, -0.3317,\n",
            "         -0.0131, -0.1660],\n",
            "        [-0.4316, -0.2825,  0.4979,  0.3525,  0.1117, -0.4154,  0.4297, -0.1031,\n",
            "         -0.3312, -0.1835],\n",
            "        [-0.3514, -0.3875,  0.3004,  0.2543, -0.2015, -0.1148, -0.0224, -0.1745,\n",
            "         -0.0507, -0.1782],\n",
            "        [-0.2525, -0.2263,  0.1872, -0.1303,  0.2125,  0.1513,  0.2712, -0.0705,\n",
            "         -0.2999, -0.1302],\n",
            "        [-0.3813, -0.3078,  0.1688,  0.1435,  0.1487,  0.1494,  0.1553,  0.0492,\n",
            "         -0.1610, -0.1348],\n",
            "        [-0.4707, -0.3278,  0.5179,  0.1582, -0.2517, -0.8252,  0.6730, -0.3209,\n",
            "         -0.4717, -0.1371],\n",
            "        [-0.8131, -0.5913, -0.1869,  0.5097,  0.1530,  0.4011,  0.3889, -0.0513,\n",
            "         -0.2964, -0.2796],\n",
            "        [-0.6971, -0.2598,  0.6605,  0.0241,  0.0891, -0.4725,  0.6968, -0.1004,\n",
            "         -0.2265, -0.2517],\n",
            "        [-0.3585, -0.2651,  0.3954, -0.0247, -0.0337, -0.3034,  0.5450, -0.4167,\n",
            "         -0.2986, -0.2984],\n",
            "        [-0.5471, -0.4258,  0.5384,  0.0743, -0.2511, -0.6443,  0.6901, -0.2217,\n",
            "         -0.3102, -0.2488]], grad_fn=<AddmmBackward>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XVLznLuRfcaN",
        "colab_type": "text"
      },
      "source": [
        "Zero the gradient buffers of all parameters and backprops with random\n",
        "gradients:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eUpR09TCfWQt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.zero_grad()\n",
        "out.backward(torch.randn(10, 10))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iAQ0u395zNNa",
        "colab_type": "text"
      },
      "source": [
        "Loss Function\n",
        "-------------\n",
        "A loss function takes the (output, target) pair of inputs, and computes a\n",
        "value that estimates how far away the output is from the target.\n",
        "\n",
        "There are several different loss functions http://pytorch.org/docs/nn.html under the\n",
        "nn package .\n",
        "A simple loss is: ``nn.MSELoss`` which computes the mean-squared error\n",
        "between the input and the target.\n",
        "\n",
        "For example:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C32eznk0z_b7",
        "colab_type": "code",
        "outputId": "13b66a80-eaeb-4d83-f488-76a0245b99e6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "target = torch.randn(10, 10)  # a dummy target, for example\n",
        "criterion = nn.MSELoss()\n",
        "\n",
        "loss = criterion(out, target)\n",
        "print(loss)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(1.1787, grad_fn=<MseLossBackward>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AP0YCtXJ0bLv",
        "colab_type": "text"
      },
      "source": [
        "Now, if you follow ``loss`` in the backward direction, using its\n",
        "``.grad_fn`` attribute, you will see a graph of computations that looks\n",
        "like this:\n",
        "\n",
        "\n",
        "    input -> fc1 -> relu -> fc2 -> MSELoss  -> loss\n",
        "\n",
        "So, when we call ``loss.backward()``, the whole graph is differentiated\n",
        "w.r.t. the loss, and all Tensors in the graph that has ``requires_grad=True``\n",
        "will have their ``.grad`` Tensor accumulated with the gradient.\n",
        "\n",
        "For illustration, let us follow a few steps backward:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L7vWeL7y0wng",
        "colab_type": "code",
        "outputId": "6a9babbd-7d33-41b2-8d75-54ccb3e2b897",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(loss.grad_fn)  # MSELoss\n",
        "print(loss.grad_fn.next_functions[0][0])  # Linear\n",
        "print(loss.grad_fn.next_functions[0][0].next_functions[0][0])  # ReLU"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<MseLossBackward object at 0x7f46d1bfae10>\n",
            "<AddmmBackward object at 0x7f46d1bfae48>\n",
            "<AccumulateGrad object at 0x7f46d1bfae10>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dVI5xNYw1hh_",
        "colab_type": "text"
      },
      "source": [
        "Backprop\n",
        "--------\n",
        "To backpropagate the error all we have to do is to ``loss.backward()``.\n",
        "You need to clear the existing gradients though, else gradients will be\n",
        "accumulated to existing gradients.\n",
        "\n",
        "\n",
        "Now we shall call ``loss.backward()``, and have a look at conv1's bias\n",
        "gradients before and after the backward.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Imr_lvvu1k_O",
        "colab_type": "code",
        "outputId": "de4f8ff0-c964-4d5f-9fe9-fbb867c32f1e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "model.zero_grad()     # zeroes the gradient buffers of all parameters\n",
        "\n",
        "print('fc1.bias.grad before backward')\n",
        "print(model.fc1.bias.grad)\n",
        "\n",
        "loss.backward()\n",
        "\n",
        "print('fc1.bias.grad after backward')\n",
        "print(model.fc1.bias.grad)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fc1.bias.grad before backward\n",
            "None\n",
            "fc1.bias.grad after backward\n",
            "tensor([-0.0006, -0.0044,  0.0501,  0.0357, -0.0167, -0.0191,  0.0358, -0.0173,\n",
            "         0.0400, -0.0256,  0.0004, -0.0032, -0.0110,  0.0080,  0.0099])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E5iohnXu1qPF",
        "colab_type": "text"
      },
      "source": [
        "Now, we have seen how to use loss functions.\n",
        "\n",
        "**Read Later:**\n",
        "\n",
        "  The neural network package contains various modules and loss functions\n",
        "  that form the building blocks of deep neural networks. A full list with\n",
        "  documentation is `here <http://pytorch.org/docs/nn>`_.\n",
        "\n",
        "**The only thing left to learn is:**\n",
        "\n",
        "  - Updating the weights of the network\n",
        "\n",
        "Update the weights\n",
        "------------------\n",
        "The simplest update rule used in practice is the Stochastic Gradient\n",
        "Descent (SGD):\n",
        "\n",
        "     ``weight = weight - learning_rate * gradient``\n",
        "\n",
        "We can implement this using simple python code:\n",
        "\n",
        "    learning_rate = 0.01\n",
        "    for f in net.parameters():\n",
        "        f.data.sub_(f.grad.data * learning_rate)\n",
        "\n",
        "However, as you use neural networks, you want to use various different\n",
        "update rules such as SGD, Nesterov-SGD, Adam, RMSProp, etc.\n",
        "To enable this, we built a small package: ``torch.optim`` that\n",
        "implements all these methods. Using it is very simple:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xc1pjqPk1uMD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "# create your optimizer\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
        "\n",
        "# in your training loop:\n",
        "optimizer.zero_grad()   # zero the gradient buffers\n",
        "output = model(input)\n",
        "loss = criterion(output, target)\n",
        "loss.backward()\n",
        "optimizer.step()    # Does the update"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GX0kmS-T2TWz",
        "colab_type": "text"
      },
      "source": [
        "Note\n",
        "\n",
        "      Observe how gradient buffers had to be manually set to zero using\n",
        "      ``optimizer.zero_grad()``. This is because gradients are accumulated\n",
        "      as explained in `Backprop`_ section."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xE386lR0RHxI",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "What about data?\n",
        "----------------\n",
        "\n",
        "Generally, when you have to deal with image, text, audio or video data,\n",
        "you can use standard python packages that load data into a numpy array.\n",
        "Then you can convert this array into a ``torch.*Tensor``.\n",
        "\n",
        "-  For images, packages such as Pillow, OpenCV are useful\n",
        "-  For audio, packages such as scipy and librosa\n",
        "-  For text, either raw Python or Cython based loading, or NLTK and\n",
        "   SpaCy are useful\n",
        "\n",
        "Specifically for vision, we have created a package called\n",
        "[torchvision](https://pytorch.org/docs/stable/torchvision/index.html), that has data loaders for common datasets such as\n",
        "Imagenet, CIFAR10, MNIST, etc. and data transformers for images, viz.,\n",
        "``torchvision.datasets`` and ``torch.utils.data.DataLoader``.\n",
        "\n",
        "This provides a huge convenience and avoids writing boilerplate code."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uam2mH9bhu8k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LZscgOOKR3Gg",
        "colab_type": "text"
      },
      "source": [
        "The output of torchvision datasets are PILImage images of range [0, 1]."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D7YiCwmnRhrK",
        "colab_type": "code",
        "outputId": "4e5e3015-b75b-4da2-ad22-12e6bc6e9cc3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 275
        }
      },
      "source": [
        "batch_size = 100\n",
        "\n",
        "# MNIST dataset (images and labels)\n",
        "train_dataset = torchvision.datasets.MNIST(root='../../data', \n",
        "                                           train=True, \n",
        "                                           transform=transforms.ToTensor(),\n",
        "                                           download=True)\n",
        "\n",
        "test_dataset = torchvision.datasets.MNIST(root='../../data', \n",
        "                                          train=False, \n",
        "                                          transform=transforms.ToTensor())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r0it [00:00, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ../../data/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "9920512it [00:01, 8096628.61it/s]                            \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting ../../data/MNIST/raw/train-images-idx3-ubyte.gz to ../../data/MNIST/raw\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "  0%|          | 0/28881 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ../../data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "32768it [00:00, 125071.39it/s]           \n",
            "  0%|          | 0/1648877 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting ../../data/MNIST/raw/train-labels-idx1-ubyte.gz to ../../data/MNIST/raw\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ../../data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "1654784it [00:00, 2052471.73it/s]                            \n",
            "0it [00:00, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting ../../data/MNIST/raw/t10k-images-idx3-ubyte.gz to ../../data/MNIST/raw\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ../../data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "8192it [00:00, 47322.18it/s]            \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting ../../data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ../../data/MNIST/raw\n",
            "Processing...\n",
            "Done!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YTrlUk1MV_QN",
        "colab_type": "text"
      },
      "source": [
        "Data Partition"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "20WxJaLGWApE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def partition_dataset(dataset, proportion=0.8):\n",
        "  n = len(dataset)\n",
        "  train_size = int(n * proportion)\n",
        "  test_size = n - train_size\n",
        "  train_dataset, val_dataset = torch.utils.data.random_split(dataset, [train_size, test_size])\n",
        "  return train_dataset, val_dataset"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ESFgJ1CnWCFw",
        "colab_type": "text"
      },
      "source": [
        "Obtain Validation Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zv5e38uQWDhS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "_train_dataset, _val_dataset = partition_dataset(train_dataset, 0.8)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p2m6fLIVV7UH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Data loader (input pipeline)\n",
        "train_loader = torch.utils.data.DataLoader(dataset=_train_dataset, \n",
        "                                           batch_size=batch_size, \n",
        "                                           shuffle=True)\n",
        "\n",
        "val_loader = torch.utils.data.DataLoader(dataset=_val_dataset, \n",
        "                                           batch_size=batch_size, \n",
        "                                           shuffle=False)\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, \n",
        "                                          batch_size=batch_size, \n",
        "                                          shuffle=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yt-febMESQKb",
        "colab_type": "text"
      },
      "source": [
        "Let us show some of the training images, for fun."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zx8aSUtaR_0c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# get some random training images\n",
        "dataiter = iter(train_loader)\n",
        "images, labels = dataiter.next() #images  (B x C x H x W), labels (B)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HpnsByJkSXwM",
        "colab_type": "code",
        "outputId": "4d06d7b7-7b90-46c3-a111-e453e0b2f6e8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# show images\n",
        "grid = torchvision.utils.make_grid(images, 10)\n",
        "npimg = grid.numpy()\n",
        "plt.imshow(np.transpose(grid, (1, 2, 0)))\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f12d76383c8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQoAAAD8CAYAAACPd+p5AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-5Reet3fWm4L",
        "colab_type": "text"
      },
      "source": [
        "# Define a Neural Network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QJmsWoh7XgCp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input_size = 784\n",
        "hidden_size = 500\n",
        "num_classes = 10\n",
        "learning_rate = 1e-8\n",
        "model = NeuralNet(input_size, hidden_size, num_classes)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qVTXZBp6XoHW",
        "colab_type": "text"
      },
      "source": [
        "Loss and Optimizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hsO1feLsSzUC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Loss and optimizer\n",
        "# nn.CrossEntropyLoss() computes softmax internally\n",
        "criterion = nn.CrossEntropyLoss()  \n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y-a41o7uYANb",
        "colab_type": "text"
      },
      "source": [
        "Train the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YJmWItqrUQ_A",
        "colab_type": "code",
        "outputId": "78ff8d84-7a11-421f-e0a5-f3c07bfd9f43",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 364
        }
      },
      "source": [
        "num_epochs = 5\n",
        "\n",
        "total_step = len(train_loader)\n",
        "for epoch in range(num_epochs):\n",
        "  for i, (images, labels) in enumerate(train_loader):\n",
        "    # Reshape images to (batch_size, input_size)\n",
        "    images = images.reshape(-1, 28*28)\n",
        "    # Forward pass\n",
        "    outputs = model(images)\n",
        "    loss = criterion(outputs, labels)\n",
        "        \n",
        "    # Backward and optimize\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "        \n",
        "    if (i+1) % 100 == 0:\n",
        "      print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}'.format(epoch+1, num_epochs, i+1, total_step, loss.item()))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch [1/5], Step [100/480], Loss: 2.3202\n",
            "Epoch [1/5], Step [200/480], Loss: 2.3034\n",
            "Epoch [1/5], Step [300/480], Loss: 2.3100\n",
            "Epoch [1/5], Step [400/480], Loss: 2.3149\n",
            "Epoch [2/5], Step [100/480], Loss: 2.3301\n",
            "Epoch [2/5], Step [200/480], Loss: 2.3031\n",
            "Epoch [2/5], Step [300/480], Loss: 2.3156\n",
            "Epoch [2/5], Step [400/480], Loss: 2.3195\n",
            "Epoch [3/5], Step [100/480], Loss: 2.3115\n",
            "Epoch [3/5], Step [200/480], Loss: 2.3122\n",
            "Epoch [3/5], Step [300/480], Loss: 2.3176\n",
            "Epoch [3/5], Step [400/480], Loss: 2.3137\n",
            "Epoch [4/5], Step [100/480], Loss: 2.3155\n",
            "Epoch [4/5], Step [200/480], Loss: 2.3122\n",
            "Epoch [4/5], Step [300/480], Loss: 2.3124\n",
            "Epoch [4/5], Step [400/480], Loss: 2.3329\n",
            "Epoch [5/5], Step [100/480], Loss: 2.3129\n",
            "Epoch [5/5], Step [200/480], Loss: 2.3231\n",
            "Epoch [5/5], Step [300/480], Loss: 2.3100\n",
            "Epoch [5/5], Step [400/480], Loss: 2.2955\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zZ7o0NiVZCX1",
        "colab_type": "text"
      },
      "source": [
        "Validate the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZsT9xu40YyaZ",
        "colab_type": "code",
        "outputId": "c8f66914-a517-493e-f921-5b27290798f6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Test the model\n",
        "# In test phase, we don't need to compute gradients (for memory efficiency)\n",
        "with torch.no_grad():\n",
        "  correct = 0\n",
        "  total = 0\n",
        "  for images, labels in val_loader:\n",
        "    images = images.reshape(-1, 28*28)\n",
        "    outputs = model(images)\n",
        "    _, predicted = torch.max(outputs.data, 1)\n",
        "    total += labels.size(0)\n",
        "    correct += (predicted == labels).sum()\n",
        "\n",
        "print('Accuracy of the model on the 10000 test images: {} %'.format(100 * correct / total))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of the model on the 10000 test images: 8 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "axp6df5GZ5Jw",
        "colab_type": "text"
      },
      "source": [
        "Training on GPU"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zTdeNOaGZbbs",
        "colab_type": "code",
        "outputId": "7faf92b5-8fba-481d-8cdf-ff8f369e139c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Assume that we are on a CUDA machine, then this should print a CUDA device:\n",
        "\n",
        "print(device)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cpu\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EPA5Z9AbaFql",
        "colab_type": "text"
      },
      "source": [
        "The rest of this section assumes that `device` is a CUDA device.\n",
        "\n",
        "Then these methods will recursively go over all modules and convert their\n",
        "parameters and buffers to CUDA tensors:\n",
        "\n",
        "\n",
        "    net.to(device)\n",
        "\n",
        "\n",
        "Remember that you will have to send the inputs and targets at every step\n",
        "to the GPU too:\n",
        "\n",
        "    inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "Why dont I notice MASSIVE speedup compared to CPU? Because your network\n",
        "is really small."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "StqeSbzEZ9K7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NGtCLSPcWHbR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VOEra7aqWHhQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}